#!/usr/bin/env python3
"""
MNISTæ•°æ®é€‰æ‹©ç»“æœå¯è§†åŒ–åˆ†æå·¥å…·
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from torchvision import datasets, transforms
from collections import Counter
import seaborn as sns

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®seabornæ ·å¼
try:
    sns.set_style("whitegrid")
    plt.style.use('seaborn-v0_8')
except:
    # å¦‚æœseaborn-v0_8ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ ·å¼
    try:
        plt.style.use('seaborn')
    except:
        pass  # ä½¿ç”¨é»˜è®¤matplotlibæ ·å¼

class MNISTResultVisualizer:
    def __init__(self, selector, train_losses, val_losses, all_weights, top_indices):
        self.selector = selector
        self.train_losses = train_losses
        self.val_losses = val_losses
        self.all_weights = all_weights
        self.top_indices = top_indices
        
        # åŠ è½½æ•°æ®é›†ç”¨äºå¯è§†åŒ–
        self.transform = transforms.Compose([transforms.ToTensor()])
        self.dataset = datasets.MNIST('data', train=True, transform=self.transform)
        
    def create_comprehensive_analysis(self):
        """åˆ›å»ºç»¼åˆåˆ†æå›¾"""
        fig = plt.figure(figsize=(20, 16))
        
        # 1. è®­ç»ƒæŸå¤±æ›²çº¿
        plt.subplot(3, 4, 1)
        self.plot_training_curves()
        
        # 2. æƒé‡åˆ†å¸ƒç›´æ–¹å›¾
        plt.subplot(3, 4, 2)
        self.plot_weight_distribution()
        
        # 3. å„æ•°å­—ç±»åˆ«æƒé‡å¯¹æ¯”
        plt.subplot(3, 4, 3)
        self.plot_class_weights()
        
        # 4. Topæ ·æœ¬æ•°å­—åˆ†å¸ƒ
        plt.subplot(3, 4, 4)
        self.plot_top_samples_distribution()
        
        # 5-8. æœ€é‡è¦æ ·æœ¬å±•ç¤º (2x2)
        self.plot_top_samples_grid(start_subplot=5)
        
        # 9. æƒé‡vsæ•°å­—ç±»åˆ«çš„ç®±çº¿å›¾
        plt.subplot(3, 4, 9)
        self.plot_weight_by_digit_boxplot()
        
        # 10. ä½æƒé‡æ ·æœ¬å±•ç¤º
        plt.subplot(3, 4, 10)
        self.plot_low_weight_samples()
        
        # 11. æƒé‡å˜åŒ–çƒ­åŠ›å›¾ï¼ˆå¦‚æœæ˜¯label_basedï¼‰
        plt.subplot(3, 4, 11)
        self.plot_class_weight_heatmap()
        
        # 12. ç»Ÿè®¡æ€»ç»“
        plt.subplot(3, 4, 12)
        self.plot_statistics_summary()
        
        plt.suptitle('MNIST Data Selection Analysis Results', fontsize=20, y=0.98)
        plt.tight_layout()
        plt.savefig('mnist_analysis_comprehensive.png', dpi=300, bbox_inches='tight')
        plt.show()
        
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        epochs = range(1, len(self.train_losses) + 1)
        
        plt.plot(epochs, self.train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=4)
        plt.plot(epochs, self.val_losses, 'r-s', label='Validation Loss (Digit 7)', linewidth=2, markersize=4)
        
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training Progress')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ è¶‹åŠ¿æ ‡æ³¨
        if len(self.train_losses) > 1:
            train_trend = "â†“" if self.train_losses[-1] < self.train_losses[0] else "â†‘"
            val_trend = "â†“" if self.val_losses[-1] < self.val_losses[0] else "â†‘"
            plt.text(0.05, 0.95, f'Train {train_trend} Val {val_trend}', 
                    transform=plt.gca().transAxes, fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.5))
    
    def plot_weight_distribution(self):
        """ç»˜åˆ¶æƒé‡åˆ†å¸ƒ"""
        plt.hist(self.all_weights, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.axvline(self.all_weights.mean(), color='red', linestyle='--', 
                   label=f'Mean: {self.all_weights.mean():.3f}')
        plt.axvline(self.all_weights.mean() + self.all_weights.std(), color='orange', 
                   linestyle='--', label=f'Mean+Std: {self.all_weights.mean() + self.all_weights.std():.3f}')
        
        plt.xlabel('Sample Weight')
        plt.ylabel('Frequency')
        plt.title('Sample Weight Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
    def plot_class_weights(self):
        """ç»˜åˆ¶å„æ•°å­—ç±»åˆ«çš„æƒé‡"""
        if self.selector.model_type == 'label_based':
            class_weights = self.selector.model.get_class_weights().detach().cpu().numpy()
            digits = list(range(10))
            
            bars = plt.bar(digits, class_weights, color='lightcoral', edgecolor='black')
            plt.xlabel('Digit Class')
            plt.ylabel('Class Weight')
            plt.title('Weight by Digit Class')
            plt.xticks(digits)
            
            # é«˜äº®æ•°å­—7
            bars[7].set_color('gold')
            bars[7].set_edgecolor('red')
            bars[7].set_linewidth(2)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, v in enumerate(class_weights):
                plt.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=8)
            
            plt.grid(True, alpha=0.3)
        else:
            plt.text(0.5, 0.5, 'Class weights not available\nfor this model type', 
                    ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('Class Weights (N/A)')
    
    def plot_top_samples_distribution(self):
        """ç»˜åˆ¶Topæ ·æœ¬çš„æ•°å­—åˆ†å¸ƒ"""
        top_labels = []
        for idx in self.top_indices[:100]:  # å–å‰100ä¸ª
            real_idx = self.selector.train_indices[idx]
            _, label = self.dataset[real_idx]
            top_labels.append(label)
        
        digit_counts = Counter(top_labels)
        digits = list(range(10))
        counts = [digit_counts.get(d, 0) for d in digits]
        
        bars = plt.bar(digits, counts, color='lightgreen', edgecolor='black')
        bars[7].set_color('gold')  # é«˜äº®æ•°å­—7
        
        plt.xlabel('Digit')
        plt.ylabel('Count in Top 100')
        plt.title('Top Samples Distribution')
        plt.xticks(digits)
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        total = sum(counts)
        for i, v in enumerate(counts):
            if v > 0:
                plt.text(i, v + 0.5, f'{v}\n({v/total*100:.1f}%)', 
                        ha='center', va='bottom', fontsize=8)
        plt.grid(True, alpha=0.3)
    
    def plot_top_samples_grid(self, start_subplot=5):
        """ç»˜åˆ¶æœ€é‡è¦æ ·æœ¬çš„2x2ç½‘æ ¼"""
        for i in range(4):
            plt.subplot(3, 4, start_subplot + i)
            
            if i < len(self.top_indices):
                real_idx = self.selector.train_indices[self.top_indices[i]]
                image, label = self.dataset[real_idx]
                weight = self.all_weights[self.top_indices[i]]
                
                plt.imshow(image.squeeze(), cmap='gray')
                plt.title(f'Rank {i+1}: Digit {label}\nWeight: {weight:.4f}', fontsize=10)
                plt.axis('off')
            else:
                plt.axis('off')
    
    def plot_weight_by_digit_boxplot(self):
        """ç»˜åˆ¶å„æ•°å­—æƒé‡çš„ç®±çº¿å›¾"""
        digit_weights = {i: [] for i in range(10)}
        
        for idx, weight in enumerate(self.all_weights):
            real_idx = self.selector.train_indices[idx]
            _, label = self.dataset[real_idx]
            digit_weights[label].append(weight)
        
        data = [digit_weights[i] for i in range(10)]
        labels = [f'{i}' for i in range(10)]
        
        box_plot = plt.boxplot(data, labels=labels, patch_artist=True)
        
        # è®¾ç½®é¢œè‰²
        colors = ['lightblue'] * 10
        colors[7] = 'gold'  # é«˜äº®æ•°å­—7
        
        for patch, color in zip(box_plot['boxes'], colors):
            patch.set_facecolor(color)
        
        plt.xlabel('Digit')
        plt.ylabel('Weight')
        plt.title('Weight Distribution by Digit')
        plt.grid(True, alpha=0.3)
    
    def plot_low_weight_samples(self):
        """å±•ç¤ºä½æƒé‡æ ·æœ¬"""
        low_indices = np.argsort(self.all_weights)[:4]  # æœ€ä½çš„4ä¸ª
        
        if len(low_indices) > 0:
            real_idx = self.selector.train_indices[low_indices[0]]
            image, label = self.dataset[real_idx]
            weight = self.all_weights[low_indices[0]]
            
            plt.imshow(image.squeeze(), cmap='gray')
            plt.title(f'Lowest Weight Sample\nDigit {label}, Weight: {weight:.4f}', fontsize=10)
            plt.axis('off')
        else:
            plt.text(0.5, 0.5, 'No low weight\nsamples found', 
                    ha='center', va='center', transform=plt.gca().transAxes)
    
    def plot_class_weight_heatmap(self):
        """ç»˜åˆ¶ç±»åˆ«æƒé‡çƒ­åŠ›å›¾"""
        if self.selector.model_type == 'label_based':
            class_weights = self.selector.model.get_class_weights().detach().cpu().numpy()
            
            # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ® (1x10)
            heatmap_data = class_weights.reshape(1, -1)
            
            im = plt.imshow(heatmap_data, cmap='YlOrRd', aspect='auto')
            plt.colorbar(im, fraction=0.046, pad=0.04)
            
            plt.yticks([0], ['Weight'])
            plt.xticks(range(10), [f'Digit {i}' for i in range(10)])
            plt.title('Class Weight Heatmap')
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(10):
                plt.text(i, 0, f'{class_weights[i]:.3f}', 
                        ha='center', va='center', fontsize=8)
        else:
            plt.text(0.5, 0.5, 'Heatmap not available\nfor this model type', 
                    ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('Weight Heatmap (N/A)')
    
    def plot_statistics_summary(self):
        """ç»˜åˆ¶ç»Ÿè®¡æ€»ç»“"""
        plt.axis('off')
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
        ğŸ“Š Training Summary
        
        Model Type: {self.selector.model_type}
        Total Samples: {len(self.all_weights):,}
        
        ğŸ“ˆ Weight Statistics
        Mean: {self.all_weights.mean():.4f}
        Std: {self.all_weights.std():.4f}
        Min: {self.all_weights.min():.4f}
        Max: {self.all_weights.max():.4f}
        
        ğŸ¯ Performance
        Final Train Loss: {self.train_losses[-1]:.4f}
        Final Val Loss: {self.val_losses[-1]:.4f}
        
        ğŸ† Top Sample Analysis
        Unique weights in top 100: {len(set(self.all_weights[self.top_indices[:100]]))}
        """
        
        plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
    
    def create_detailed_sample_analysis(self):
        """åˆ›å»ºè¯¦ç»†çš„æ ·æœ¬åˆ†æå›¾"""
        fig, axes = plt.subplots(4, 10, figsize=(20, 8))
        fig.suptitle('Top 40 Most Important Samples for Digit 7 Recognition', fontsize=16)
        
        for i in range(40):
            row = i // 10
            col = i % 10
            
            if i < len(self.top_indices):
                real_idx = self.selector.train_indices[self.top_indices[i]]
                image, label = self.dataset[real_idx]
                weight = self.all_weights[self.top_indices[i]]
                
                axes[row, col].imshow(image.squeeze(), cmap='gray')
                axes[row, col].set_title(f'#{i+1}\nDigit: {label}\nW: {weight:.3f}', fontsize=8)
                axes[row, col].axis('off')
                
                # å¦‚æœæ˜¯æ•°å­—7ï¼Œç”¨çº¢è‰²è¾¹æ¡†
                if label == 7:
                    for spine in axes[row, col].spines.values():
                        spine.set_edgecolor('red')
                        spine.set_linewidth(2)
            else:
                axes[row, col].axis('off')
        
        plt.tight_layout()
        plt.savefig('mnist_top_samples_detailed.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def analyze_result_insights(self):
        """åˆ†æç»“æœæ´å¯Ÿ"""
        print("\n" + "="*60)
        print("ğŸ” MNISTæ•°æ®é€‰æ‹©ç»“æœåˆ†æ")
        print("="*60)
        
        # åˆ†ææƒé‡åˆ†å¸ƒ
        unique_weights = len(set(self.all_weights))
        print(f"ğŸ“Š æƒé‡ç»Ÿè®¡:")
        print(f"   - ç‹¬ç‰¹æƒé‡æ•°é‡: {unique_weights:,}")
        print(f"   - æ€»æ ·æœ¬æ•°é‡: {len(self.all_weights):,}")
        print(f"   - æƒé‡åˆ†å¸ƒèŒƒå›´: [{self.all_weights.min():.6f}, {self.all_weights.max():.6f}]")
        
        # åˆ†æTopæ ·æœ¬
        top_labels = []
        for idx in self.top_indices[:100]:
            real_idx = self.selector.train_indices[idx]
            _, label = self.dataset[real_idx]
            top_labels.append(label)
        
        digit_counts = Counter(top_labels)
        print(f"\nğŸ† Top 100æ ·æœ¬åˆ†æ:")
        for digit in sorted(digit_counts.keys()):
            percentage = digit_counts[digit] / 100 * 100
            print(f"   - æ•°å­— {digit}: {digit_counts[digit]} ä¸ª ({percentage:.1f}%)")
        
        # åˆ†ææ¨¡å‹è¡Œä¸º
        print(f"\nğŸ§  æ¨¡å‹è¡Œä¸ºåˆ†æ:")
        if self.selector.model_type == 'label_based':
            class_weights = self.selector.model.get_class_weights().detach().cpu().numpy()
            highest_weight_digit = np.argmax(class_weights)
            print(f"   - æœ€é«˜æƒé‡ç±»åˆ«: æ•°å­— {highest_weight_digit} (æƒé‡: {class_weights[highest_weight_digit]:.6f})")
            print(f"   - æ•°å­—7çš„æƒé‡: {class_weights[7]:.6f}")
            print(f"   - æƒé‡æ¯”å€¼ (æ•°å­—7/å¹³å‡): {class_weights[7]/class_weights.mean():.2f}x")
            
            # è§£é‡Šä¸ºä»€ä¹ˆæ‰€æœ‰Topæ ·æœ¬æƒé‡ç›¸åŒ
            if unique_weights <= 10:
                print(f"\nğŸ’¡ ç»“æœè§£é‡Š:")
                print(f"   - ä½¿ç”¨label_basedæ¨¡å‹ï¼ŒåŒä¸€æ•°å­—çš„æ‰€æœ‰æ ·æœ¬æƒé‡ç›¸åŒ")
                print(f"   - æ•°å­—7è·å¾—æœ€é«˜æƒé‡ {class_weights[7]:.6f}")
                print(f"   - å› æ­¤æ‰€æœ‰æ•°å­—7æ ·æœ¬éƒ½æ˜¯'æœ€é‡è¦'çš„æ ·æœ¬")
                print(f"   - è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆTopæ ·æœ¬éƒ½æ˜¯æ•°å­—7ä¸”æƒé‡ç›¸åŒ")


def visualize_mnist_results(selector, train_losses, val_losses, all_weights, top_indices):
    """ä¸»å‡½æ•°ï¼šå¯è§†åŒ–MNISTç»“æœ"""
    
    print("ğŸ¨ æ­£åœ¨ç”Ÿæˆè¯¦ç»†çš„å¯è§†åŒ–åˆ†æ...")
    
    visualizer = MNISTResultVisualizer(selector, train_losses, val_losses, all_weights, top_indices)
    
    # åˆ›å»ºç»¼åˆåˆ†æå›¾
    print("ğŸ“Š ç”Ÿæˆç»¼åˆåˆ†æå›¾...")
    visualizer.create_comprehensive_analysis()
    
    # åˆ›å»ºè¯¦ç»†æ ·æœ¬åˆ†æ
    print("ğŸ” ç”Ÿæˆè¯¦ç»†æ ·æœ¬åˆ†æ...")
    visualizer.create_detailed_sample_analysis()
    
    # æ‰“å°åˆ†ææ´å¯Ÿ
    visualizer.analyze_result_insights()
    
    print("\nâœ… å¯è§†åŒ–åˆ†æå®Œæˆ!")
    print("ğŸ“ å·²ä¿å­˜å›¾ç‰‡æ–‡ä»¶:")
    print("   - mnist_analysis_comprehensive.png (ç»¼åˆåˆ†æ)")
    print("   - mnist_top_samples_detailed.png (è¯¦ç»†æ ·æœ¬åˆ†æ)")


if __name__ == "__main__":
    print("è¿™æ˜¯ä¸€ä¸ªå¯è§†åŒ–å·¥å…·æ¨¡å—ï¼Œè¯·ä»ä¸»ç¨‹åºè°ƒç”¨ visualize_mnist_results() å‡½æ•°") 